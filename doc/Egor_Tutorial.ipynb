{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "72380b9b",
   "metadata": {},
   "source": [
    "# Using _egobox_ optimizer _Egor_"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "31022791",
   "metadata": {},
   "source": [
    "## Installation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1504e619-5775-42d3-8f48-7339272303ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: egobox in d:\\rlafage\\miniconda3\\lib\\site-packages (0.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install egobox"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4c2757f5",
   "metadata": {},
   "source": [
    "We import _egobox_ as _egx_ for short."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0edaf00f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import egobox as egx"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c8c8c84",
   "metadata": {},
   "source": [
    "You may setup the logging level to get optimization progress during the execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "af2d82be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# To display optimization information (none by default)\n",
    "# import logging\n",
    "# logging.basicConfig(level=logging.INFO)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "22997c39",
   "metadata": {},
   "source": [
    "## Example 1 : Continuous optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "faae2555",
   "metadata": {},
   "source": [
    "### Test functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f6da807",
   "metadata": {},
   "outputs": [],
   "source": [
    "xspecs_xsinx = egx.to_specs([[0., 25.]])\n",
    "n_cstr_xsinx = 0\n",
    "\n",
    "def xsinx(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.atleast_2d(x)\n",
    "    y = (x - 3.5) * np.sin((x - 3.5) / (np.pi))\n",
    "    return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c436437",
   "metadata": {},
   "outputs": [],
   "source": [
    "xspecs_g24 = egx.to_specs([[0., 3.], [0., 4.]])\n",
    "n_cstr_g24 = 2\n",
    "\n",
    "# Objective\n",
    "def G24(point):\n",
    "    \"\"\"\n",
    "    Function g24\n",
    "    1 global optimum y_opt = -5.5080 at x_opt =(2.3295, 3.1785)\n",
    "    \"\"\"\n",
    "    p = np.atleast_2d(point)\n",
    "    return - p[:, 0] - p[:, 1]\n",
    "\n",
    "# Constraints < 0\n",
    "def G24_c1(point):\n",
    "    p = np.atleast_2d(point)\n",
    "    return (- 2.0 * p[:, 0] ** 4.0\n",
    "            + 8.0 * p[:, 0] ** 3.0 \n",
    "            - 8.0 * p[:, 0] ** 2.0 \n",
    "            + p[:, 1] - 2.0)\n",
    "\n",
    "def G24_c2(point):\n",
    "    p = np.atleast_2d(point)\n",
    "    return (-4.0 * p[:, 0] ** 4.0\n",
    "            + 32.0 * p[:, 0] ** 3.0\n",
    "            - 88.0 * p[:, 0] ** 2.0\n",
    "            + 96.0 * p[:, 0]\n",
    "            + p[:, 1] - 36.0)\n",
    "\n",
    "# Grouped evaluation\n",
    "def g24(point):\n",
    "    p = np.atleast_2d(point)\n",
    "    return np.array([G24(p), G24_c1(p), G24_c2(p)]).T\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "45641636",
   "metadata": {},
   "source": [
    "### Continuous optimization with _Egor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c8942031",
   "metadata": {},
   "outputs": [],
   "source": [
    "egor = egx.Egor(g24, xspecs_g24, \n",
    "                     n_doe=10, \n",
    "                     n_cstr=n_cstr_g24, \n",
    "                     cstr_tol=[1e-3, 1e-3],\n",
    "                     infill_strategy=egx.InfillStrategy.WB2,\n",
    "                     target=-5.5,\n",
    "                     # outdir=\"./out\",\n",
    "                     # hot_start=True\n",
    "                    )  # see help(egor) for options\n",
    "\n",
    "# Specify regression and/or correlation models used to build the surrogates of objective and constraints\n",
    "#egor = egx.Egor(g24, xlimits_g24, n_cstr=n_cstr_g24, n_doe=10,\n",
    "#                      regr_spec=egx.RegressionSpec.LINEAR,\n",
    "#                      corr_spec=egx.CorrelationSpec.MATERN32 | egx.CorrelationSpec.MATERN52)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c12b8e9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization f=[-5.50837809e+00  3.84933482e-04  3.56699512e-04] at [2.329518   3.17886009]\n",
      "Optimization history: \n",
      "Inputs = [[2.14941171 1.2022835 ]\n",
      " [2.89591634 3.04421182]\n",
      " [1.13129495 3.27983113]\n",
      " [2.50882074 2.47459348]\n",
      " [1.34917886 1.15978118]\n",
      " [1.99449618 0.14570364]\n",
      " [1.68323092 3.96900812]\n",
      " [0.26740239 1.98981025]\n",
      " [0.823056   0.52179224]\n",
      " [0.34794318 2.23644392]\n",
      " [2.3323044  3.09159185]\n",
      " [2.32962545 3.17922313]\n",
      " [2.329518   3.17886009]]\n",
      "Outputs = [[-3.35169521e+00 -1.00398765e+00 -2.62111904e+00]\n",
      " [-5.94012816e+00 -1.24186360e+01  2.88844914e+00]\n",
      " [-4.41112609e+00 -6.51809729e-01  3.03904161e+00]\n",
      " [-4.98341421e+00 -2.78451535e+00  2.77667993e-01]\n",
      " [-2.50896004e+00 -2.38224715e+00 -1.69313518e-01]\n",
      " [-2.14019982e+00 -1.85453736e+00 -3.85405403e+00]\n",
      " [-5.65223904e+00  1.40041321e+00  7.31474755e-01]\n",
      " [-2.25721264e+00 -4.39484898e-01 -1.40405159e+01]\n",
      " [-1.34484824e+00 -3.35493157e+00 -7.17152437e-02]\n",
      " [-2.58438710e+00 -4.24396527e-01 -9.72535570e+00]\n",
      " [-5.42389625e+00 -1.09766687e-01 -7.37742400e-02]\n",
      " [-5.50884858e+00 -1.29446921e-04  1.22477349e-03]\n",
      " [-5.50837809e+00  3.84933482e-04  3.56699512e-04]]\n"
     ]
    }
   ],
   "source": [
    "res = egor.minimize(n_iter=30)\n",
    "print(f\"Optimization f={res.y_opt} at {res.x_opt}\")\n",
    "print(\"Optimization history: \")\n",
    "print(f\"Inputs = {res.x_hist}\")\n",
    "print(f\"Outputs = {res.y_hist}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fb8ddd3d",
   "metadata": {},
   "source": [
    "## Example 2 : Mixed-integer optimization"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d46259b3",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6948efc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "xspecs_mixint_xsinx = [egx.XSpec(egx.XType.INT, [0, 25])]\n",
    "n_cstr_mixint_xsinx = 0\n",
    "\n",
    "def mixint_xsinx(x: np.ndarray) -> np.ndarray:\n",
    "    x = np.atleast_2d(x)\n",
    "    if (np.abs(np.linalg.norm(np.floor(x))-np.linalg.norm(x))< 1e-8):\n",
    "        y = (x - 3.5) * np.sin((x - 3.5) / (np.pi))\n",
    "    else:\n",
    "        raise ValueError(f\"Bad input: mixint_xsinx accepts integer only, got {x}\")\n",
    "    return y"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "67faa229",
   "metadata": {},
   "source": [
    "### Mixed-integer optimization with _Egor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "928d1f38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization f=[-15.12161154] at [19.]\n",
      "Optimization history: \n",
      "Inputs = [[ 7.]\n",
      " [24.]\n",
      " [11.]\n",
      " [ 6.]\n",
      " [ 5.]\n",
      " [ 4.]\n",
      " [17.]\n",
      " [18.]\n",
      " [19.]]\n",
      "Outputs = [[  3.14127616]\n",
      " [  4.91604976]\n",
      " [  5.1356682 ]\n",
      " [  1.78601478]\n",
      " [  0.68929352]\n",
      " [  0.07924194]\n",
      " [-12.35295142]\n",
      " [-14.43198471]\n",
      " [-15.12161154]]\n"
     ]
    }
   ],
   "source": [
    "egor = egx.Egor(mixint_xsinx, xspecs_mixint_xsinx, \n",
    "                     n_doe=3, \n",
    "                     infill_strategy=egx.InfillStrategy.EI,\n",
    "                     target=-15.12,\n",
    "                    )  # see help(egor) for options\n",
    "res = egor.minimize(n_iter=30)\n",
    "print(f\"Optimization f={res.y_opt} at {res.x_opt}\")\n",
    "print(\"Optimization history: \")\n",
    "print(f\"Inputs = {res.x_hist}\")\n",
    "print(f\"Outputs = {res.y_hist}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b9747211",
   "metadata": {},
   "source": [
    "## Example 3 : More mixed-integer optimization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fe3a862",
   "metadata": {},
   "source": [
    "In the following example we see we can have other special integer type cases, where a component of x can take one value out of a list of ordered values (ORD type) or being like an enum value (ENUM type). Those types differ by the processing related to the continuous relaxation made behind the scene:\n",
    "* For INT type, resulting float is rounded to the closest int value,\n",
    "* For ORD type, resulting float is cast to closest value among the given valid ones,\n",
    "* For ENUM type, one hot encoding is performed to give the resulting value.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7d3511",
   "metadata": {},
   "source": [
    "### Test function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f1615d5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Objective function which takes [FLOAT, ENUM1, ENUM2, ORD] as input\n",
    "# Note that ENUM values are passed as indice value eg either 0, 1 or 2 for a 3-sized enum  \n",
    "def mixobj(X):\n",
    "    # float\n",
    "    x1 = X[:, 0]\n",
    "    #  ENUM 1\n",
    "    c1 = X[:, 1]\n",
    "    x2 = c1 == 0\n",
    "    x3 = c1 == 1\n",
    "    x4 = c1 == 2\n",
    "    #  ENUM 2\n",
    "    c2 = X[:, 2]\n",
    "    x5 = c2 == 0\n",
    "    x6 = c2 == 1\n",
    "    # int\n",
    "    i = X[:, 3]\n",
    "\n",
    "    y = (x2 + 2 * x3 + 3 * x4) * x5 * x1 + (x2 + 2 * x3 + 3 * x4) * x6 * 0.95 * x1 + i\n",
    "    return y.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa3c4223",
   "metadata": {},
   "source": [
    "### Mixed-integer optimization with _Egor_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d14fff89",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Optimization f=[-14.25] at [-5.  2.  1.  0.]\n",
      "Optimization history: \n",
      "Inputs = [[-1.90197486  2.          1.          3.        ]\n",
      " [ 1.36933896  1.          0.          2.        ]\n",
      " [-0.10843099  1.          0.          0.        ]\n",
      " [-4.73477511  0.          0.          3.        ]\n",
      " [ 3.11266243  2.          1.          2.        ]\n",
      " [ 0.33069418  2.          1.          0.        ]\n",
      " [ 4.47594664  2.          1.          0.        ]\n",
      " [-3.26619512  0.          0.          2.        ]\n",
      " [-5.          2.          1.          2.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          1.          0.          0.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          2.          1.          0.        ]\n",
      " [-5.          2.          1.          0.        ]]\n",
      "Outputs = [[ -2.42062836]\n",
      " [  4.73867792]\n",
      " [ -0.21686197]\n",
      " [ -1.73477511]\n",
      " [ 10.87108792]\n",
      " [  0.9424784 ]\n",
      " [ 12.75644793]\n",
      " [ -1.26619512]\n",
      " [-12.25      ]\n",
      " [-14.25      ]\n",
      " [-14.25      ]\n",
      " [-14.25      ]\n",
      " [-14.25      ]\n",
      " [-10.        ]\n",
      " [-14.25      ]\n",
      " [-14.25      ]\n",
      " [-14.25      ]\n",
      " [-14.25      ]]\n"
     ]
    }
   ],
   "source": [
    "xtypes = [\n",
    "    egx.XSpec(egx.XType.FLOAT, [-5.0, 5.0]),\n",
    "    egx.XSpec(egx.XType.ENUM, tags=[\"blue\", \"red\", \"green\"]),\n",
    "    egx.XSpec(egx.XType.ENUM, xlimits=[2]),\n",
    "    egx.XSpec(egx.XType.ORD, [0, 2, 3]),\n",
    "]\n",
    "egor = egx.Egor(mixobj, xtypes, seed=42)\n",
    "res = egor.minimize(n_iter=10)\n",
    "print(f\"Optimization f={res.y_opt} at {res.x_opt}\")\n",
    "print(\"Optimization history: \")\n",
    "print(f\"Inputs = {res.x_hist}\")\n",
    "print(f\"Outputs = {res.y_hist}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "705bf10d",
   "metadata": {},
   "source": [
    "Note that `x_opt` result contains indices for corresponding optional tags list hence the second component should be read as 0=\"red\", 1=\"green\", 2=\"blue\", while the third component was unamed 0 correspond to first enum value and 1 to the second one."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b9fadfa",
   "metadata": {},
   "source": [
    "## Usage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b91f14f2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Help on Egor in module builtins object:\n",
      "\n",
      "class Egor(object)\n",
      " |  Egor(fun, xspecs, n_cstr=0, cstr_tol=None, n_start=20, n_doe=0, doe=None, regr_spec=Ellipsis, corr_spec=Ellipsis, infill_strategy=Ellipsis, q_points=1, par_infill_strategy=Ellipsis, infill_optimizer=Ellipsis, kpls_dim=None, n_clusters=1, target=Ellipsis, outdir=None, hot_start=False, seed=None)\n",
      " |  \n",
      " |  Optimizer constructor\n",
      " |  \n",
      " |  fun: array[n, nx]) -> array[n, ny]\n",
      " |       the function to be minimized\n",
      " |       fun(x) = [obj(x), cstr_1(x), ... cstr_k(x)] where\n",
      " |          obj is the objective function [n, nx] -> [n, 1]\n",
      " |          cstr_i is the ith constraint function [n, nx] -> [n, 1]\n",
      " |          an k the number of constraints (n_cstr)\n",
      " |          hence ny = 1 (obj) + k (cstrs)\n",
      " |       cstr functions are expected be negative (<=0) at the optimum.\n",
      " |  \n",
      " |   n_cstr (int):\n",
      " |       the number of constraint functions.\n",
      " |  \n",
      " |   cstr_tol (list(n_cstr,)):\n",
      " |       List of tolerances for constraints to be satisfied (cstr < tol), list size should be equal to n_cstr.\n",
      " |       None by default means zero tolerances.\n",
      " |  \n",
      " |   xspecs (list(XSpec)) where XSpec(xtype=FLOAT|INT|ORD|ENUM, xlimits=[<f(xtype)>] or tags=[strings]):\n",
      " |       Specifications of the nx components of the input x (eg. len(xspecs) == nx)\n",
      " |       Depending on the x type we get the following for xlimits:\n",
      " |       * when FLOAT: xlimits is [float lower_bound, float upper_bound],\n",
      " |       * when INT: xlimits is [int lower_bound, int upper_bound],\n",
      " |       * when ORD: xlimits is [float_1, float_2, ..., float_n],\n",
      " |       * when ENUM: xlimits is just the int size of the enumeration otherwise a list of tags is specified\n",
      " |         (eg xlimits=[3] or tags=[\"red\", \"green\", \"blue\"], tags are there for documention purpose but\n",
      " |          tags specific values themselves are not used only indices in the enum are used hence\n",
      " |          we can just specify the size of the enum, xlimits=[3]),\n",
      " |  \n",
      " |   n_start (int > 0):\n",
      " |       Number of runs of infill strategy optimizations (best result taken)\n",
      " |  \n",
      " |   n_doe (int >= 0):\n",
      " |       Number of samples of initial LHS sampling (used when DOE not provided by the user).\n",
      " |       When 0 a number of points is computed automatically regarding the number of input variables\n",
      " |       of the function under optimization.\n",
      " |  \n",
      " |   doe (array[ns, nt]):\n",
      " |       Initial DOE containing ns samples:\n",
      " |           either nt = nx then only x are specified and ns evals are done to get y doe values,\n",
      " |           or nt = nx + ny then x = doe[:, :nx] and y = doe[:, nx:] are specified  \n",
      " |  \n",
      " |   regr_spec (RegressionSpec flags, an int in [1, 7]):\n",
      " |       Specification of regression models used in gaussian processes.\n",
      " |       Can be RegressionSpec.CONSTANT (1), RegressionSpec.LINEAR (2), RegressionSpec.QUADRATIC (4) or\n",
      " |       any bit-wise union of these values (e.g. RegressionSpec.CONSTANT | RegressionSpec.LINEAR)\n",
      " |  \n",
      " |   corr_spec (CorrelationSpec flags, an int in [1, 15]):\n",
      " |       Specification of correlation models used in gaussian processes.\n",
      " |       Can be CorrelationSpec.SQUARED_EXPONENTIAL (1), CorrelationSpec.ABSOLUTE_EXPONENTIAL (2),\n",
      " |       CorrelationSpec.MATERN32 (4), CorrelationSpec.MATERN52 (8) or\n",
      " |       any bit-wise union of these values (e.g. CorrelationSpec.MATERN32 | CorrelationSpec.MATERN52)\n",
      " |  \n",
      " |   infill_strategy (InfillStrategy enum)\n",
      " |       Infill criteria to decide best next promising point.\n",
      " |       Can be either InfillStrategy.EI, InfillStrategy.WB2 or InfillStrategy.WB2S.\n",
      " |  \n",
      " |   q_points (int > 0):\n",
      " |       Number of points to be evaluated to allow parallel evaluation of the function under optimization.\n",
      " |  \n",
      " |   par_infill_strategy (ParInfillStrategy enum)\n",
      " |       Parallel infill criteria (aka qEI) to get virtual next promising points in order to allow\n",
      " |       q parallel evaluations of the function under optimization.\n",
      " |       Can be either ParInfillStrategy.KB (Kriging Believer),\n",
      " |       ParInfillStrategy.KBLB (KB Lower Bound), ParInfillStrategy.KBUB (KB Upper Bound),\n",
      " |       ParInfillStrategy.CLMIN (Constant Liar Minimum)\n",
      " |  \n",
      " |   infill_optimizer (InfillOptimizer enum)\n",
      " |       Internal optimizer used to optimize infill criteria.\n",
      " |       Can be either InfillOptimizer.COBYLA or InfillOptimizer.SLSQP\n",
      " |  \n",
      " |   kpls_dim (0 < int < nx)\n",
      " |       Number of components to be used when PLS projection is used (a.k.a KPLS method).\n",
      " |       This is used to address high-dimensional problems typically when nx > 9.\n",
      " |  \n",
      " |   n_clusters (int >= 0)\n",
      " |       Number of clusters used by the mixture of surrogate experts.\n",
      " |       When set to 0, the number of cluster is determined automatically and refreshed every\n",
      " |       10-points addition (should say 'tentative addition' because addition may fail for some points\n",
      " |       but it is counted anyway).\n",
      " |  \n",
      " |   target (float)\n",
      " |       Known optimum used as stopping criterion.\n",
      " |  \n",
      " |   outdir (String)\n",
      " |       Directory to write optimization history and used as search path for hot start doe\n",
      " |  \n",
      " |   hot_start (bool)\n",
      " |       Start by loading initial doe from <outdir> directory\n",
      " |  \n",
      " |   seed (int >= 0)\n",
      " |       Random generator seed to allow computation reproducibility.\n",
      " |  \n",
      " |  Methods defined here:\n",
      " |  \n",
      " |  minimize(self, /, n_iter=20)\n",
      " |      This function finds the minimum of a given function `fun`\n",
      " |      \n",
      " |      # Parameters\n",
      " |          n_iter:\n",
      " |              the iteration budget, number of fun calls is n_doe + q_points * n_iter.\n",
      " |      \n",
      " |      # Returns\n",
      " |          optimization result\n",
      " |              x_opt (array[1, nx]): x value  where fun is at its minimum subject to constraint\n",
      " |              y_opt (array[1, nx]): fun(x_opt)\n",
      " |  \n",
      " |  ----------------------------------------------------------------------\n",
      " |  Static methods defined here:\n",
      " |  \n",
      " |  __new__(*args, **kwargs) from builtins.type\n",
      " |      Create and return a new object.  See help(type) for accurate signature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "help(egor)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
